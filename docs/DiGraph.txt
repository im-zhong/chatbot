第一章 项目背景（根据项目实际情况修改）
近年来，各行各业的信息化推进产生了大量业务数据，同时，科学技术的发展让数据存储和计算效率有了飞跃式提升，“人工智能”，这个在计算机诞生早期就提出的概念，终于迎来普及和飞速发展的机会。被称为“AI进步的阶梯”的图谱，也受到了越来越多的关注。
以节点和关系组成的图谱，是一种基础而通用的表现语言，不仅能“高保真”地表达这个多姿多彩世界的各种关系，更能非常直观、高效地描述真实世界中的各个业务场景。不需要中间过程的转换和处理——而这种中间过程的转换和处理，往往把问题复杂化，或遗漏掉很多有价值的信息。
第二章 总体设计
2.1.	总体架构
智图·DiGraph是一套全生命周期知识图谱引擎产品，从多模态源数据的接入，到多模态数据感知，再到知识抽取，从而构建一套动态高可用的知识图谱，并提供丰富的图计算挖掘分析工具，最终为知识的应用奠定基础。为维持整套系统的稳定，我们提供完备的平台管理功能，使得用户在知识图谱全流程生命周期中保证系统稳定与完整。
数据源模块：智图·DiGraph提供多源异构数据的接入，包括结构化数据、半结构化数据及非结构化数据。
数据感知模块：多源数据接入后智图·DiGraph会根据数据类型进行分类，按照不同的模态数据进行不同的数据感知任务划分，例如对图像数据进行识别，分类。对语音数据分帧，抽取等感知，形成一系列行业标签或实体库。
知识抽取模块：在感知数据的基础上或在源数据基础上利用 NLP 技术，对数据进行抽取、消歧、融合等知识流程。
知识管理模块：对已经提取的知识进行体系的构建，并融合行业特性形成符合领域场景的知识体系建模，以构建行业本体复用与各行各业，并依照国际存储标准提供知识体系存储机制。
图计算挖掘模块：图谱的价值很大一部分是利用图的计算能力进行挖掘与发现，这些能力在业务场景中多用于风险预测，社群发现，模式匹配等特定的领域。智图·DiGraph提供基于图论的基础图计算模块，例如出入度、中心度分析，图直径、离散度计算等。同时支持基于图表示的机器学习算法，例如频繁子图、社群发现等。内置并集成了学界成熟的数十种算法模型，为更丰富的场景提供强大的挖掘计算能力。
知识应用模块：基于上述完备的技术储备与功能架构，智图·DiGraph 为行业提供一系列知识应用，例如关联分析、智能问答、智能推荐、推理预测、辅助决策等应用。

 
2.2.	产品技术架构
 

智图·DiGraph提供一套知识管理标准，N种存储解决方案，对图库提供中间层封装的技术方案，以方便兼容市场上主流的图库，并可达到多图库支持并灵活转换的技术支持。智图·DiGraph的Z类智能技术融合，为知识图谱全生命周期中的各个要素提供稳健的技术支持， 基于此智图·DiGraph可灵活运用在各个领域。

第三章 建设方案
基于海量行业内容语料数据和行业知识积累，支持知识图谱的构建、管理和展示分析，可为用户分析、人物关系图谱等提供工具支撑。
通过积累的人物、社会、经济、文化等知识，具备百万级以上实体数量，千万级以上关系数，这些能力将沉淀至智慧中台服务于各业务应用。
通过知识图谱构建，对单位从内外部接入的结构化数据、非结构化数据、半结构化的数据，进行数据预处理和数据抽取，进而存储计算，以达到最大程度的利用和挖掘数据资产的价值的目的。基于海量行业内容语料数据和行业知识积累，实现知识图谱的构建、管理和展示分析，可为用户分析、人物关系图谱等提供工具支撑。
通过丰富的可视化展示界面以及强大的分析功能，可快速将分散的海量多样数据，进行智能分析和挖掘关联；并将全量数据归一为业务理解的语言和图形，最大化的还原了数据的本质。能够在海量实体、关系网中，实时进行关系挖掘、路径推演、全文检索等，通过强大灵活的交互，提供全新的数据分析解决方案。
知识图谱旨在实现更智能的搜索引擎，随着智能信息服务应用的不断发展，知识图谱已被广泛应用于智能搜索、智能问答、个性化推荐、情报分析、反欺诈等领域。另外，通过知识图谱能够将Web上的信息、数据以及链接关系聚集为知识，使信息资源更易于计算、理解以及评价，并且形成一套Web语义知识库。知识图谱以其强大的语义处理能力与开放互联能力，可为万维网上的知识互联奠定扎实的基础，使Web 3.0提出的“知识之网”愿景成为了可能。
知识图谱：是结构化的语义知识库，用于迅速描述物理世界中的概念及其相互关系。
知识图谱通过对错综复杂的文档的数据进行有效的加工、处理、整合，转化为简单、清晰的“实体,关系,实体”的三元组，最后聚合大量知识，从而实现知识的快速响应和推理。
知识图谱有自顶向下和自底向上两种构建方式。所谓自顶向下构建是借助百科类网站等结构化数据源，从高质量数据中提取本体和模式信息，加入到知识库中；所谓自底向上构建，则是借助一定的技术手段，从公开采集的数据中提取出资源模式，选择其中置信度较高的新模式，经人工审核之后，加入到知识库中。
构建一套贴合业务，融合异源异构数据的图谱平台，面临巨大的技术、人力、资金等成本，而建成之后再进行 调整优化，又会是一个费时费力的工作。本项目所设计的知识图谱平台是一个集计算、查询、 存储、可视化等于一体的图引擎平台，支持多数据源接入、多本体模型编辑、多图谱、多应用、多用户，拥有 数据灵活映射、指标统计、子图匹配和推理规则配置、权限分级、资源管理、可视化组件、为业务应用提供一套标准API等，是一套扩展性和适用性极佳的图谱中间件。 
客户在构建图谱平台、打造基于图谱的大数据分析系统时使用系统图引擎，将大大节省系统的搭 建时间和成本，用户只需要融合异源异构数据，系统图引擎将在分钟级别内生成图谱，为企业和行 业用户节省了调研、代码、图谱功能开发的时间和人力，大大提升资源使用效率。 
系统可广泛应用于金融、公安、军事、卫生、反恐、社交、营销等领域。
通过知识图谱构建，对机构从内外部接入的结构化数据、非结构化数据、半结构化的数据，进行数据预处理和数据抽取，进而存储计算，以达到最大程度的利用和挖掘数据资产的价值的目的。基于海量行业内容语料数据和行业知识积累，实现知识图谱的构建、管理和展示分析，可为用户分析、人物关系图谱等提供工具支撑。
针对动态本体的五元组重新组装为概念管理、属性管理、关系体系管理三个功能模块。数据被抽象为“实体-关系-实体”、“实体-关系-事件”等三元组形式，根据不同的数据对象类型，使用最合适的存储方式以及对应的查询方式，包括图存储、列式存储、索引存储等。通过丰富的可视化展示界面以及强大的分析功能，可快速将分散的海量多样数据，进行智能分析和挖掘关联；并将全量数据归一为业务理解的语言和图形，最大化的还原了数据的本质。能够在海量实体、关系网中，实时进行关系挖掘、路径推演、全文检索等，通过强大灵活的交互，提供全新的数据分析解决方案。
 
知识图谱框架示意图
系统提供一套知识管理标准，多种存储解决方案，对图库提供中间层封装的技术方案，以方便兼容市场上主流的图库，并可达到多图库支持并灵活转换的技术支持。系统的多类智能技术融合，为知识图谱全生命周期中的各个要素提供稳健的技术支持，基于此系统可灵活运用在各个领域。
多语种知识图谱系统是一套全生命周期知识图谱引擎产品，从多模态源数据的接入，到多模态数据感知，再到知识抽取，从而构建一套动态高可用的知识图谱，并提供丰富的图计算挖掘分析工具，最终为知识的应用奠定基础。为维持整套系统的稳定， 我们提供完备的平台管理功能，使得用户在知识图谱全流程生命周期中保证系统稳定与完整。
数据源模块：系统提供多源异构数据的接入，包括结构化数据、半结构化数据及非结构化数据。
数据感知模块：多源数据接入后系统会根据数据类型进行分类，按照不同的模态数据进行不同的数据感知任务划分，例如对图像数据进行识别，分类。对语音数据分帧，抽取等感知，形成一系列行业标签或实体库。
知识抽取模块：在感知数据的基础上或在源数据基础上利用NLP技术，对数据进行抽取、消歧、融合等知识流程。
知识管理模块：对已经提取的知识进行体系的构建，并融合行业特性形成符合领域场景的知识体系建模，以构建行业本体复用与各行各业，并依照国际存储标准提供知识体系存储机制。
图计算挖掘模块：图谱的价值很大一部分是利用图的计算能力进行挖掘与发现，这些能力在业务场景中多用于风险预测，社群发现，模式匹配等特定的领域。系统提供基于图论的基础图计算模块，例如出入度、中心度分析，图直径、离散度计算等。同时支持基于图表示的机器学习算法，例如频繁子图、社群发现等。内置并集成了学界成熟的数十种算法模型，为更丰富的场景提供强大的挖掘计算能力。
知识应用模块：基于上述完备的技术储备与功能架构，为行业提供一系列知识应用，例如关联分析、智能问答、智能推荐、推理预测、辅助决策等应用。
3.1.	本体建模与知识管理
3.1.1.	本体建模
根据业务实际需求划分本体，本体是指工人的概念集合、概念框架，如“人”、“事”、“物”等。
本体管理可以采用人工编辑的方式手动构建，也可以以数据驱动的自动化方式构建本体。因为人工方式工作量巨大，且很难找到符合要求的专家，因此当前主流的全局本体库产品，都是从一些面向特定领域的现有本体库出发，采用自动构建技术逐步扩展得到的。
自动化本体构建过程包含三个阶段：
	实体并列关系相似度计算
	实体上下位关系抽取
	本体的生成
实现基于OWL描述语言的符合动态本体规范的知识图谱人工建模工具，
并实现基于RDF描述语言的知识图谱内容管理工具。
Core基于现有的通用领域知识、垂直领域知识构建知识图谱，重点在知识图谱的工程化技术栈的建立和配套工程人员技术体系建设。特别地，该工具不能集成文档管理等相关功能，这会导致系统整体复杂性大幅提高。不考虑自动化地从外部数据中利用自然语言处理等技术挖掘知识实体、实体关系等信息。
知识图谱对数据的规范化要求非常高，因此知识建模功能将动态本体技术融合到系统中，并针对动态本体的五元组重新组装为概念管理、属性管理、关系体系管理三个功能模块。在此基础上，将标签体系集成到知识建模功能中，集中化管理文档的标签体系。

3.1.1.1.	本体推理
 
本体推理规则管理
推理规则定义提供当前本体内所有推理规则的清单，并提供推理规则的增删改查功能。 
推理规则完全遵守SWRL（Semantic Web Rule Language）规范，针对常用的关系推理和属性推理规则提供推理规则的可视化定义功能，用户无需深入学习该规则语言的文法即可完成规则配置工作。
3.1.1.2.	概念定义管理
提供可视化的知识建模界面，规范化地定义知识图谱中的各类概念（人物、组织、事件，以及自定义的概念），并对这些概念所能具有的属性名称、数据类型、取值范围进行规范化的定义。在进行概念管理的过程中，首先需要定义的是概念的名称，以及概念所隶属的父概念，通过这种层次化的管理方式可以有效地刻画现实世界中事物的存在方式；其次对概念所拥有的属性进行“挂载”操作，通过从属性池中选择经过规范化定义的属性，能够有效保障概念定义的规范性。
3.1.1.3.	属性定义管理 
 
 属性管理
属性管理作为概念定义过程中所涉及的所有属性的来源，采用池化的管理方式将所有概念能够“挂载”的属性进行统一管理，并按照数据所属的数据类型进行分类管理。通过这种严格的属性管理方式，可以有效的保障上层概念定义的规范化，以及知识图谱中知识实体信息的规范性。现有的属性数据类型包括：字符串型、枚举型、时间型、时间区间型、键值型、整数型、小数型，并在支持上述基本数据类型的基础上，提供表单型属性定义的支持，用于描述工作经历等具有多个子属性的情况，实现概念定义过程中对属性的强规范性约束。
3.1.1.4.	关系定义管理 
关系体系是概念所对应的知识实体能够建立的关联关系的规范性定义。通过关系体系的 定义，能够有效地对概念之间的关联关系进行规范化的约束，对动态本体的全局规范性提供 基础保障。基于规范性的关系体系定义，为动态本体赋予基于规则的知识推理的原力，为深度挖掘文档内容中存在的潜在信息提供知识层面的支撑。 
3.1.1.5.	多模态知识建模
文档属性建模:提供文档作为概念属性的建模能力，支持该能力后实体属性中可存储并展示文档；
图片属性建模：提供图片作为概念属性的建模能力，支持该能力后实体属性中可存储并展示图片；
视频属性建模：提供视频作为概念属性的建模能力，支持该能力后实体属性中可存储并展示视频；
音频属性建模：提供音频作为概念属性的建模能力，支持该能力后实体属性中可存储并展示音频。
3.1.2.	知识管理
图谱管理模块提供知识图谱的管理功能，包括对于图谱基本信息的管理功能。对于图谱内的知识和关系，这些知识数据的管理操作，在图谱编辑模块进行操作。 
图谱管理功能提供对图谱基本信息的管理和编辑功能。 
本功能提供所有图谱清单的展示功能，并且允许对清单中的图谱进行删改查功能，同时允许新增图谱。 
对于图谱，产品提供图谱的查询、新建、编辑、删除，共计4项操作功能。 
其中，新建指的是创建一个新的图谱，此时该图谱并不包括任何实际知识数据，仅包括基本信息；仅在新建时可以选择新建本体或者使用已有本体，如果需要新建本体则会跳转到本体管理界面继续新建本体的流程，否则基于选择的已有本体进行创建，目前一个图谱仅支持一个本体。编辑，指的是对该图谱的基本信息进行修改。删除，指的是删除该图谱，相应的知识和关系等数据也将被一并删除，删除的过程是异步的，由后台自动清理垃圾数据。
3.1.2.1.	知识管理 
知识管理功能提供对图谱内知识数据、关系数据的管理功能。 
3.1.2.2.	关系体系
关系体系是概念所对应的知识实体能够建立的关联关系的规范性定义。通过关系体系的 定义，能够有效地对概念之间的关联关系进行规范化的约束，对动态本体的全局规范性提供 基础保障。基于规范性的关系体系定义，为动态本体赋予基于规则的知识推理的原力，为深度挖掘文档内容中存在的潜在信息提供知识层面的支撑。 
3.1.2.3.	知识融合
提供人工的实体融合入口，对同概念实体可进行实体属性和实体关系的合并，用户可决定保留的具体属性列表。
3.1.2.4.	资源管理
3.1.2.4.1.	资源管理
非结构化构图数据源管理：对某图谱下的原文文档提供管理功能，包含文档目录管理，文档搜索，文档标签等。
多模态资源管理：对用户在实体中上传的多模态资源进行管理，可搜索，删除，分类等，包含文档、图片、视频、音频资源。
3.1.2.4.2.	知识标注
实体标注：提供人机交互的形式进行知识标注，行业专家可对机器标注结果进行干预，提供在原文文档中直接标注实体。
属性标注：提供人机交互的形式进行知识标注，，行业专家可在原文中标注属性并挂载至某具体实体。
关系标注：提供人机交互的形式进行知识标注，行业专家可对机器标注结果进行干预，提供在该模块添加文档中实体关系的能力。
关键词标注：对文档篇章进行关键词添加。
文档打标：对文档篇章进行达标体系标注。
3.2.	本体中心
3.2.1.	本体中心
提供对业务中所有创建本体的综合管理中心，该中心可以做本体资产的管理与共享。
3.2.2.	本体复制
本题中心中的本体可无限复制，快速复用与业务。
3.2.3.	本体管理
提供对本体中心中所有本体的管理能力，包括本体的增删改查等。
3.3.	自动化图谱构建
图谱构建模块作为连接数据和知识的重要支撑平台，主要解决知识图谱的可视化构图问题，面向结构化数据、非结构化数据以及三元组形式的数据，实现数据到知识的映射与抽取，实现数据到知识的快速转变，为企业提供人性化、交互友好的可视化知识图谱构建通用平台。
3.3.1.	图谱构建任务管理 
图谱构建模块以任务为驱动实现自动化、可视化的知识构建，系统针对图谱构建任务实现全生命周期管理，包括构建任务的新建、发布、执行、卸载、停止、删除等一系列操作。用户通过任务总览从多角度感知任务的统计信息，通过任务管理，实现任务的新建、发布、执行以及停止等管理功能，下图为图谱构建任务管理图。
 
图谱构建任务管理图

(1) 结构化构图任务配置
结构化构图任务配置，需经由本体模型、数据源、知识映射三个步骤，通过确定领域本体，接入用户结构化数据，以及结合已选领域本体和接入的用户结构化数据表，通过手动可视化配置数据表与概念属性、概念关系的映射规则，实现实体映射及关系映射，建立结构化数据转化为知识映射规则，通过后端图谱构建任务，实现数据的转化并存入图数据库。
(2)非结构化构图任务配置
非结构化构图任务配置，需经由知识本体、数据接入、知识抽取、知识过滤、知识融合以及知识入库等步骤，通过确定领域本体，接入用户存储于数据库或本体的非结构化文本数据，经由知识抽取组件，抽取出实体、属性、关系以及事件三元组，经过知识过滤，获取高质量知识，再经由知识融合，解决知识冗余、冲突问题，最后将知识存储入库，形成知识图谱。
(3) RDF文件构图任务配置
RDF文件构图，允许用户将本地序列化好的RDF三元组数据直接导入形成适配系统的实体、关系表达三元组，存储入库，支持OWL、RDF、TTL、Json-ld等格式。
3.3.2.	结构化数据构建 
结构化数据的构图流程首先需要确定构建目标图谱的领域本体（即领域知识体系），明确目标图谱的知识组织形式、边界及规范；接着根据图谱构建的数据需求，接入用户的结构化数据；最后结合已选领域本体和接入的用户结构化数据，通过知识映射转化为三元组知识，形成知识图谱。结构化构图任务配置模块提供给用户可视化地、无编程化地实现结构化数据构图流程的映射配置，以进一步指导及推进后端图谱构建任务。
结构化构图任务配置模块分为本体模型、数据源、知识映射等三个功能模块，本体模型模块提供本体模型的选择；数据源模块提供对数据源及数据表的配置；知识映射模块提供数据转化为知识的映射规则配置。
 
结构化构图任务配置功能模块图
(1)本体模型
通过本体模型约束而形成的知识图谱不仅层次结构较强，并且冗余程度较小。所以，在构建知识图谱之前，需要先具备知识本体模型，用于确定所构建的知识图谱共同认可的知识边界、概念，以及这些概念和概念之间相互关系的明确定义。
本体模块包括：选择本体、本体概念属性展示、本体关系属性展示、导入映射配置等功能，如下图所示。
 
结构化数据构建本体模型配置图
 (2)数据源
知识图谱构建的前提是获取数据，结构化的数据通常存储在用户公司内的数据库或本地表格文件中。知识图谱构建过程中，在确定好领域本体后，需要基于对业务的理解，配置数据源，导入结构化数据。数据源配置模块包括：链接数据源、选取数据表、数据表字段配置等功能。根据业务数据的存储来源，进行数据源配置，进行包括但不限于SQL Server、Mysql、Elastic等数据库类型的数据接入，接入后支持用户选取目标数据表，针对每个目标数据表进行数据表字段配置，包括唯一标识符字段配置、跨表字段配置，如下图所示。
 
结构化数据构建数据源配置图
 (3)知识映射
知识映射模块实现结构化数据表与关联知识的语义模式映射，即建立结构化业务数据与知识图谱领域本体的映射关系。用户通过便捷的页面交互即可实现知识映射的配置，知识映射配置包括实体映射、关系映射、运行映射、提交等功能，如下图所示。
 
 结构化数据构建知识映射配置图
3.3.3.	非结构化数据构建 
将非结构化数据处理的NLP流程进行抽象成为流程算子，可视化的通过拖拽，算子组合等方式实现源数据的知识工程处理全流程，包括实体抽取、关系抽取、实体消歧、实体融合， 经过上述算子流程处理后可直接一键成图。 非结构化数据的构图流程首先需要确定构建目标图谱的领域本体（即领域知识体系），明确目标图谱的知识组织形式、边界及规范；然后根据图谱构建的数据需求，接入用户的结构化数据或非结构化数据；接着通过机器自动化或人工辅助机器半自动化地从非结构化文本数据中抽取实体、属性、关系及事件相关领域知识；并结合已选领域本体和知识抽取的结构化数据，通过知识过滤，形成高质量三元组知识，最后通过知识融合操作，对知识库知识进一步提炼、规约，形成知识图谱。非结构化构图任务配置模块为用户提供自由拖拽流程组件、自主定义流程节点实现非结构化构图流程的流水线设计功能，非结构化构图任务流程如下图所示。
 
非结构化构图流程
非结构化构图任务配置模块分为流程节点、数据接入、知识抽取、知识过滤、知识融合等五个功能模块。流程节点，提供用户对知识本体、知识入库节点的拖拽及设置，用户可通过知识本体组件，设置该非结构化构图流程中的领域本体，可通过知识入库设置构图结束时，导入图库的相关设置；数据接入，提供给用户设置数据接入，可接入结构化数据、非结构化数据；知识抽取组件提供实体抽取、属性抽取、关系抽取、事件抽取等流程的设置，可选择一个和多个联合抽取组件，通过选择相应的算法模型来实现抽取；知识过滤组件提供给用户选择相应的知识过滤规则来过滤抽取结果，以便形成高质量的知识；知识融合组件，通过选择相应的融合规则或算法模型实现知识的消歧、链接，形成较为完备、高质量的知识图谱。
 
非结构化构图任务配置功能模块图
非结构化构图任务配置采用流水线进行配置，非结构化构图流水线是非结构化构图任务的一个预定义任务配置流程，可以让用户自定义流程节点，后端根据用户定义的流程执行非结构化构图任务。
流水线有且只有一个开始节点、一个结束节点，开始节点是本体模型，结束节点是知识入库。流水线必须是一个有向无环图。流水线由一系列的预定义组件组成，这些组件包含知识抽取组件（实体/关系/属性抽取）、知识过滤组件、知识映射、知识融合组件等。
 
非结构化流水线图
非结构化构图任务流程，非结构化构图流水线包含流程节点、数据接入、知识抽取、知识过滤、知识融合等内容。
(1)流程节点
流程节点包含知识本体、知识入库功能节点。知识本体节点，通过引入领域本体模型，确定所构建的知识图谱共同认可的知识边界、概念，以及这些概念和概念之间相互关系的明确定义。该节点包括：本体概念属性展示、本体关系属性展示等功能。知识入库节点，提供将非结构化构建的数据存入图数据库进行存储。
(2)数据接入
数据接入包含结构化数据、非结构化数据的接入。其中结构化数据支持关系型数据表及CSV格式的数据接入。非结构化数据接入，支持TXT文本数据接入，可通过上传文件接入，也可直接从远程对象数据库中直接拉取非结构化文本数据。
(3)知识抽取
面向非结构化数据的知识抽取的研究主要是面向文本进行抽取，其首要步骤是进行实体识别，然后对文本进行关系抽取、属性抽取、事件抽取等后续步骤，完成知识三元组的抽取。同时，针对文档的抽取，系统中还提供文档摘要抽取、关键词抽取、文档要素抽取，为后续深度分析非结构化文档提供基础支撑。
在非结构化数据的知识抽取部分，系统采用解耦的方式，用户可根据自己实际业务场景去选择知识抽取各个类别下的不同的算法模型，将其替换，来更好的支撑用户的业务。 这些算法模型分为：实体抽取、关系抽取、关键词抽取、文档摘要抽取、文档要素抽取、实体及关系抽取等几大类别，用户可根据不同的业务选择不同类别下的算法模型进行相关知识的抽取。
(4)知识过滤
针对抽取后的知识，一般需要进行知识过滤，过滤掉一些不合法、脏数据之后，提高知识的可用性。系统采用解耦的方式，用户可根据自己实际业务场景去选择不同的知识过滤规则及算法模型，将其替换，来更好的支撑用户的业务。
(5)知识融合
在构建知识图谱时，入库之前一般需要进行知识融合，解决数据的冲突及歧义问题。知识融合通常需要处理两个层面的融合：通过模式层的融合，将新得到的本体融入已有的本体库中，以及新旧本体的融合；数据层的融合，包括实体的指称、属性、关系以及所属类别等，主要的问题是如何避免实例以及关系的冲突问题，造成不必要的冗余。
数据层的融合是指实体和关系（包括属性）元组的融合，主要是实体匹配或者对齐，由于知识库中有些实体含义相同但是具有不同的标识符，因此需要对这些实体进行合并处理。系统采用解耦的方式，用户可根据自己实际业务场景去选择不同的知识融合规则及算法模型，将其替换，来更好的支撑用户的业务。
3.3.4.	三元组形式的数据构建
三元组形式的数据构建，即RDF文件构图任务，提供给用户将本地序列化的RDF文件快速转换为知识图谱引擎系统中的实体、关系组织形式，存储入库，目前系统中支持的RDF序列化文件格式包含owl、rdf、xml、ttl、json-ld等格式。
RDF(Resource Description Framework)，即资源描述框架，其本质是一个数据模型（Data Model）。具体地，
Resource：页面、图片、视频等任何具有URI标识符的资源。
Description：属性、特征和资源之间的关系。
Framework：模型、语言和这些描述的语法。
它提供了一个统一的标准，用于描述实体/资源。RDF形式上表示为SPO三元组，有时候也称为一条语句（statement），知识图谱中我们也称其为一条知识，如下图所示。
 
三元组示意图
RDFS(Resource Description Framework Schema)用于对RDF进行类似的类定义及其属性的定义。RDFS本质上是RDF词汇的一个扩展，OWL(Web Ontology Language)又是RDFS的一个扩展，添加了额外的预定义词汇，是语义网技术栈的核心之一。OWL有两个主要的功能：一是提供快速、灵活的数据建模能力，二是具有高效的自动推理能力。
RDF文件构图分为文件上传、文件列表两个模块。
文件上传模块包括拖拽文件上传及浏览文件上传方式，用户可以直接拖拽owl、rdf、xml、ttl、json-ld等格式文件进行上传，也可以通过浏览电脑中文件夹选择文件，上传满足相应格式的文件。
文件列表中包含用户上传的文件展示，包含添加文件、清空列表、文件展示、删除文件、构图范围设置、提交等模块。添加文件模块，允许用户增加上传文件；清空列表代表，用户可清空文件列	表中用户上传的多个文件；删除文件，允许用户删除选中文件；构图范围设置，需要用户针对上传的RDF文件设置其构图范围，文件类型共包括：概念体系、属性约束、关系定义、推理规则、知识实体、实体关系等六种类型，每个文件可以设置为这六种类型中的一种或多种类型，代表着该文件所声明数据的涵盖范围，后端程序依据此文件类型设置，准确解析文件中的数据，形成实体、关系，连接成图，存储入库。
 
RDF文件构图任务配置功能模块图
RDF文件构图功能拥有一下特性：
(1) 提供一键上传，自动解析RDF文件成图功能
(2) 全覆盖RDF序列化文件格式，包括：
.owl(OWL/XML文件)
.rdf(RDF/XML文件)
.nt(N-Triples文件)
.ttl(Tutle文件)
.json/jsonld(JSON-LD语法的JSON文件)
(3)多文件同步解析，同时构建本体及知识实例。
图谱构建模块提供RDF文件构图功能，将RDF文件中的三元组数据通过图谱构建模块将具有RDF定义标准的序列化文件无缝映射到GraphLake系统中成图展示，如下图所示。
 
三元组数据构图任务配置
3.3.5.	任务配置模板管理 
系统中的结构化、非结构化以及三元组形式的数据构建需要根据不同的任务类型进行相应的任务配置，每种任务类型所进行的配置流程及配置操作是不相同的，且需要用户根据不同的源数据以及目标图谱进行相应的任务配置，模板管理中心根据不同任务提供任务配置模板，因三元组形式的数据构建一般采用本地上传文件方式构建图谱，没有模板约束，所以任务配置模板管理中心提供结构化构图模板与非结构化构图两类模板的管理，提供针对结构化以及非结构化构图任务模板的新建、搜索、导出、更新、删除、配置详情查看等功能，下图为结构化构图模板管理与非结构化构图模板管理图。
 
结构化构图模板管理图
 
非结构化构图模板管理图
3.4.	关联分析
系统提供知识图谱搜索功能，在用户检索过程中，核心环节是如何将用户的检索输入与知识图谱进行交互。首先，需要系统将用户输入的自然语言检索式、实体对或知识库查询语句，转化成查询子图并与整个知识图谱进行匹配。随后，检索系统将识别检索式中的语义实体，并对实体间的结构关系进行查询扩展与推理。最后，系统对检索处理的结果进行相关性的排序，将最能符合用户需求的结果提供给用户，基于知识图谱搜索的流程如下图所示。
 
 知识图谱的检索流程
知识图谱搜索功能，包括知识实体搜索、关系搜索、高级搜索以及实体属性搜索等功能，用户通过知识搜索，获取目标知识，系统将搜索结果可视化地呈现在界面上，提供给用户查阅，以进行下一步有目标的深度分析，其搜索结果展示如下图所示。
 
搜索结果可视化效果图
实体搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体的名称信息，进而根据实体名称找到知识库中对应的知识条目，以知识卡片的形式进行展示。知识实体搜索功能包括基于名称的知识实体搜索、基于别名的知识实体搜索、知识实体详情展示等内容。
关系搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体名称和实体关系名称，进而根据实体名称和关系名称找到知识库中对应的关联知识条目，以知识节点以及相关联知识节点的形式进行展示。包括基于名称的知识关联搜索、基于别名的知识关联搜索、知识关联详情等内容。
实体属性搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体名称和实体属性名称，进而从知识库中获取实体的属性值作为问题的答案返回，并在界面中返回答案涉及的知识实体节点。包括基于名称的知识实体属性搜索、基于别名的知识实体属性搜索、知识实体属性详情等内容。
3.4.1.	交互可视化
交互可视化工具提供多种展示方式来展现图谱网络，包括环形、动力、分层和网格布局等。该工具不仅仅可展示实体间的时间序列关系，这些时间视图还可以用来说明事件随着时间的推移如何展开。它们不仅帮助揭示实体之间的相互作用，而且还描绘这些相互作用何时发生。
 
 

3.4.2.	图计算挖掘
图计算模块提供图指标（KPI）、关系推理规则的配置、子图定义和匹配、计算任务的 管理等功能，可以覆盖目前常见的图挖掘和分析需求。GraphLake 将用户定义的规则自动进行定期计算，并将计算结果显示到图谱中。
GraphLake 提供两类计算指标，计数类和计算类指标。基于用户定义的本体模型，通过定义计数类指标，用户可计算两度内，与某一中心节点相关的节点个数，如某公司的法人代表对外任职的公司数量；以及计算两度内，与某一中心节点相关的关系数，如个人拥有的所有股票账户与另一对手账户之间的交易次数。通过计算类指标，用户可统计两度内，某节点或某节点关联的边的某项属性，如持股公司发行的债权中 AA+ 以下的数量统计（节点的属性计算），个人持有的所有银行账户对境外账户转账金额之和（边的属性计算）。根据用户定义本体模型的不同，指标可计算目标图谱节点的各类指标。
 

 
用户可自定义关系推理规则：如根据两节点的属性推理出新的关系——两个公司产品相 同，推测两公司可能有竞争关系；如根据两节点间的已有关系推理出新的关系——两个公司 有贷款转账关系，则两公司一定有上下游关系；如根据两个节点与某中心节点间的关系推理出新的关系——两公司投了同一个标，则两公司一定有竞争关系。根据用户定义本体模型的不同，Graph Lake 能从已有信息中推理出业务场景的各类新关系。
 
用户可自定义多种子图结构模式：自定义阶数、关系类型、节点类型、属性等复杂模式，通过对图的顶点个数和标号的限定，把频繁子图挖掘转化为传统频繁项集的挖掘，根据用户定义的子图模式，发现包括但不限于“三方循环相互投资”、“交叉互惠投资”、“内幕交易”等多种典型的图结构模式。
 
3.4.3.	时序分析
若实体，关系中存在时间属性只支持对某实体的关系时序脉络分析，并提供时序时间筛选等功能。
3.4.4.	指标计算
对图谱中节点进行指标计算，例如节点出入度，中心度，中介度等。
3.4.5.	路径探寻
探索两个实体之间的最短路径，探索两个实体之间的所有度数路径。
3.4.6.	自定义路径探寻
以某些实体或关系条件进行限定的路径探寻。
3.4.7.	节点排名Pagerank算法
节点排名，查找网络中重要节点。
3.4.8.	社群发现LPA算法
标签传播的社团发现，发现群组或社群。
3.4.9.	GIS 分析
Graph Lake 的交互可视化工具更提供 GIS 组件和应用。以地图的方式展示图谱上节点在空间上的分布和关联性。空间数据的拓扑关系为数据分析提供地理视角的线索，结合时间序列，进行时空分析，可为进一步追踪事件、对象随时间在空间上的变更轨迹提供良好的可视化和交互体验。
3.4.10.	时空分析
传统图谱分析方式通常将时间分析与空间分析相隔离，然而在行业实际应用中，时间与空间的相互影响案例十分常见，GraphLake 为此提供了时空分析解决方案，使得数据在时间维度和空间维度上的存在与变化更加具象。通过时空变化探寻更高维度的数据分析价值。
3.4.10.1.	GIS图谱分析
对于含GIS属性的实体或关系，进行空间维度分析，可进行地图范围搜索、实体测距、实体热力分布等功能。
3.4.10.2.	GIS轨迹分析
查看空间维度上实体的行为变化及路径轨迹的分析。
3.4.11.	用户权限
GraphLake 支持对每个图谱项目进行独立灵活的权限管理。管理者可设置成员在每个不同图谱中的角色权限，保证同一成员在不同项目中的权限控制，灵活进出。
 
3.4.12.	实体搜索
与传统的以网页页面集合方式呈现的搜索结果不同，知识实体搜索关注的是知识实体对象，对象可以是人、组织等概念类别下的知识实体，知识实体搜索的结果是知识实体对象或知识实体对象集合。
系统提供基于名称的知识实体卡片搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体的名称信息，进而根据实体名称找到知识库中对应的知识条目，以知识卡片的形式进行展示。
系统提供相关及相似知识实体的搜索，根据用户输入的关键词或者自然语言描述的查询，通过搜索引擎模型理解用户意图，输出查询语句，从后端知识库中找到对应知识实体对象。知识实体搜索的具体流程如下图所示，首先针对用户输入语句进行自然语言理解分析，然后通过查询语句检索出候选实体，再对候选实体进行排序后，得到检索结果。
知识实体搜索的功能，提供给用户查询搜索框，并能够直接展示搜索结果列表的展示。其具体功能包括以下内容：
 (1)基于名称的知识实体搜索
系统提供基于名称的知识实体搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体的名称信息，进而根据实体名称找到知识库中对应的知识实体节点，对知识实体节点进行展示。
 (2)基于别名的知识实体搜索
系统提供基于别名的知识实体卡片搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体的别名信息，进而根据实体别名找到知识库中对应的知识条目，以知识节点的形式进行展示。
 (3)知识实体详情展示
对于搜索到的知识条目，系统支持从知识库系统中获取知识实体的详细信息，并在搜索结果展示的右边展示知识实体详情。
 
实体详情展示图
3.4.13.	关系搜索
对于用户输入的问题，首先利用问题解析模型进行解析，根据模型输出从知识库中找到对应的知识实体及对应知识关联，即能够从搜索条件中识别出知识库中存在的知识实体的名称以及实体关系名称，并能够找到知识库中对应的知识实体和关系实体。系统提供知识关联知识搜索功能，该功能具体包含以下内容：
 (1)基于名称的关系搜索
系统提供基于名称的知识关联搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体名称和实体关系名称，进而根据实体名称和关系名称找到知识库中对应的关联知识条目，以知识节点以及相关联知识节点的形式进行展示。
(2)基于别名的关系搜索
系统提供基于别名的知识关联搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体的别名信息和关系实例，进而根据实体别名和关系实例找到知识库中关联的知识实体以及关系实例，进行展示。
(3)关系详情展示
对于搜索到的关联知识，系统支持从知识库系统中获取知识实体的详细信息，并在搜索结果画布中展示知识实体节点以及知识实体关系实例信息，双击关系实例即可查看关系实例的属性详情。
 
关系详情展示图
3.4.14.	实体属性搜索
对于用户输入的问题，首先利用问题解析模型进行解析，根据模型输出从知识库中找到对应的知识实体及对应属性。并在搜索结果列表顶端展示该属性内容以及该知识实体的信息。系统提供知识实体属性搜索功能，该功能具体包含以下内容：
 (1)基于名称的实体属性搜索
系统提供基于名称的知识实体属性搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体名称和实体属性名称，进而从知识库中获取实体的属性值作为问题的答案返回，并在界面中返回答案涉及的知识实体节点。
 (2)基于别名的实体属性搜索
系统提供基于别名的知识实体属性搜索功能，支持对用户输入的问题进行解析，从搜索条件中识别出知识库中存储的知识实体的别名信息和属性信息，进而从知识库中获取实体的属性值作为问题的答案返回，以知识节点的形式进行展示。
 (3)实体属性详情展示
对于根据实体属性搜索到的知识，系统支持从知识库系统中获取知识实体相关的属性详细信息，并在搜索结果列表顶端展示该知识实体的信息，双击实体查看实体属性详情。
 
实体属性详情展示图
3.4.15.	高级搜索
高级搜索功能面向具有更加精准的搜索需要的专业用户，系统提供基于有限逻辑组合的高级搜索功能。
用户可以通过限定时间范围对查询目标知识集合进行初次限制，对于知识实体及关系的结构、内容等方面的查询条件，系统提供可视化的查询条件组合界面，为用户提供基于选择-输入的查询条件自动生成功能。
在高级搜索条件组合功能中，系统提供用户自由定义的多个条件之间的逻辑组合功能，包括AND、OR、NOT三种逻辑组合方式，并支持条件的分组组合，实现基于多项式的高级搜索条件的组合方式。下图为系统提供的高级搜索功能，用户可根据实体筛选条件，对实体的类型、属性等字段进行有限条件的自由组合；同时，也能根据关系筛选条件，对关系的类型、属性等字段进行有限条件的自由组合，实现高级搜索功能。
 
高级搜索条件组合示意图
3.4.16.	统计计算
提供对于实体和关系分类的基础统计计算能力。
3.4.17.	3D图谱视图
提供关联关系的3D可视化展示形式。

3.4.18.	高级渲染模块
高级渲染模块，旨在通过可视化的节点或边的渲染，实现快速从海量数据中锁定目标节点，包含4个功能：属性渲染功能、聚合渲染功能、优化显示功能和分组展示功能。
3.4.18.1.	属性渲染
属性渲染是指利用属性之进行分类计算，将计算结果中等值的节点进行二次渲染，同时以等值的属性作为节点分类布局的依据，将节点重新进行分类布局的方法。该方法四要素如下：
1、属性中需存在int或float类型数据，以作为计算基础。
2、对某一类节点进行计算，保证其可比性。
3、自动分类采取GCN算法对节点进行分类计算。
4、手动分类可指定属性值的归属范围，已完成定制的分类。
3.4.18.2.	聚合渲染
对于同类特征节点的组合，同样的在实际业务场景中，会遇到如下情形；一个账户存在多笔交易记录。诈骗电话存在大量的通联记录。这些行为通常以关系定义，那么便存在同类特征的关系。同样为简化图谱分析的视觉压力与操作复杂度，系统可以将同类特征的关系聚合成为一条关系展示。聚合关系有两大基础：同向关系和同类关系。
3.4.18.3.	优化显示
优化显示功能，将关联图谱中复杂的一些展示优化显示。
3.4.18.4.	分组展示
分组展示，通过定义分组模式，将同类实体分组展示。在以往项目经验的累积中，发现金融场景常出现的某一类特征，即某一账户存在大量的交易对手方。而安全场景中，会发现某一诈骗电话存在大量的通联记录。投资场景中，存在着谱系家族投资人出现的事实。在数据分析角度而言，此类节点通常具有某一类相同的特征。可作为某一重点对象而进行分析。然而图谱数据量过大，使得重点数据量过大，在分析过程中造成视觉压力、操作不便捷。未解决此类问题，系统利用了分组概念，用户可通过某一相同元素特征来自定义元素分组。
3.4.19.	应用展示模块
基于基础布局模块和高级渲染模块，形成知识卡片、搜索视图、结果视图、关联视图、文档视图、统计视图等应用展示模块
3.4.19.1.	知识卡片
通过可视化人机交互方式，提供单个节点或单个关系的知识卡片查看，展示包括名称、别称、概况、国别、描述、子描述等内容，并支持内容的修改、刷新和管理。
 
知识卡片图
3.4.19.2.	搜索视图
通过可视化人机交互方式，提供实体、关系、属性等内容的检索查看功能。
 
搜索视图
3.4.19.3.	结果视图
基于搜索关键词，形成对应的结果视图，同时支持搜索内容关联检索功能。
 
结果视图
3.4.19.4.	关联视图
基于可视化人机交互方式，通过选定一条关系，可查看关联内容，包括关系ID、关系类型、关系名称、关系别名、权重值、关系主体、关系客体等内容，并支持内容的修改、刷新和管理。
 
关联视图
3.4.19.5.	文档视图
基于可视化人机交互方式，通过选定一个节点或实体，可查看其源头文档相关内容。
 
文档视图
3.4.19.6.	统计视图
通过可视化人机交互方式，可以查看单项知识图谱的数据总览，包括实体总个数、实体各类别数量统计、关系总条数、关系各类别数量统计、以及图例情况，方便用户了解概况。
 
 统计视图

3.4.20.	多场景图谱展示
 输入实体、关系等关键字以层级形式展示知识图谱的关系，用户点击实体可查看其属性，提供关系拓展和挖掘分析功能，提供通过划词进行数据清分的功能、UI细节需在验收前根据用户要求修改。
3.4.20.1.	基础布局模块
基础布局模块，旨在通过基础的可视化布局方式，对关联图谱进行分析，包含4个功能：环形布局功能、力学布局功能、分层布局功能、网格布局功能。
3.4.20.2.	环形布局
环形布局（Circular Layout）将不同节点进行分层和排列到多个圆环上，主要用于发现每个节点与其它节点之间的关系。高度规范化的将节点放置在一个圆上，非常清晰地描绘每个单独的节点，且一个节点不会被另一个节点遮挡。
环形布局算法的核心思路为计算中心性最高的节点，将其置于环形中心，与其相连接的点按照一定的顺序置于邻近的圆周上，然后按照这种策略布局余下的节点，直至所有的节点布局完毕。
对于显示一个对象的高关联度优势很大，常用于社交网络、电商交易等突破分析。
 
环形布局图
3.4.20.3.	力学布局
力学布局（Force Directed Layout）是通过算法进行多次迭代，调整引力和斥力等参数，将图谱稀疏和稠密的网络结构展示出来；力导向布局得出的图往往美观，表现出对称性，而且有利于生成较少交叉边的布局平面图。力学布局图在社交网络研究、信息传播途径研究、社群发现等领域应用广泛，它可以直观反映群体与群体之间联系的渠道、交集、群体内部的联系强度等。
作为一种可以应用于复杂网络布局的算法，力学布局被广泛应用。力学布局算法功能计算只依赖于包含在图本身结构中的信息来进行图形布局，而不依赖特定领域的知识。算法将节点看成互排斥的粒子，边看做节点间的相互吸引作用力，当系统达到平衡时，没有联系的节点将互相远离，联系紧密的节点则倾向于聚集造一起。
力学布局在于体现节点的同质性，具有共同交集越多的节点，它们聚在一起的可能性越高；而处于中心位置的几个节点则是这些节点的中心，该功能利于寻找社交网络中信息的源头或者比较有社会影响力的人。
 
力学布局图
3.4.20.4.	分层布局
分层布局（Hierarchical Layout），将图谱元素以关系流向顺序从上至下地排列，节点将以分层的结构展现，适用于发现对象间的层次关系，特别适用于追踪资金流动轨迹和股权结构分析等场景。
分层布局算法功能通过节点的层次及边的方向来布局，节点从上到下、从左至右的节点距离相同，使得一些具有上下游关系、或者层级关系的数据在是图上显性的表达出来。该功能可配置分层逻辑类型，如按中心性分层、按时间先后分层和按类型进行分层，实现从多角度对图谱元素进行分层，满足不同维度的分析研判需求。
 
分层布局图
3.4.20.5.	网格布局
网格布局（Grid Layout）使图谱上所有元素在当前屏幕内作矩阵式整齐排列，减少视觉噪音，专注分析追踪。网格布局能更清晰查看当前画布中元素的数量规模，便于对每个节点做各种操作、移动节点，进而看到节点间的密度差异。
网格布局算法功能将布局空间均匀地划分为网格，然后将节点放置在这些网格中，避免节点重叠；以广度优先的方式遍历所有的数据，然后按照遍历的顺序以行优先的策略依次放置在网格中；同时根据网络的全局拓扑关系确定节点间的相互作用的立场参数，使得联系密切、图距离小的节点之间的几何距离也尽可能小，从而相对聚集的节点在视图上形成集团，网格布局算法具有速度快、节点排列整齐等优势。
 
网格布局图
第四章 非功能性指

1、支持两个实体之间路径探寻不低于3阶
2、支持网络中的节点至少3层（含3层）以上下钻分析
3、支持不少于5层级知识体系构建
4、支持图谱存储与计算能力达到百亿节点、千亿边规模
5、支持ShortestPath、NoLoopPath、AllPath路径算法在数分钟内完成计算
6、单节点直接扩线可在3s内响应
7、单节点筛选扩线可在6s内响应
8、按照名称查询知识实体可在5s内响应
9、按照属性查询知识实体可在8s内响应
第五章 案例
5.1.	“天镜”数智金融平台
让计算机通过可视界面定义企业的各类属性，并动态描绘出企业属性之间的关联关系，方便使用者直观地理解和建立目标企业的特征体系。智图领域知识大脑接入银行信贷数据完成知识图谱构建，通过企业资金流向网络、资金流动时序、企业间关联关系的分析，识别存在信贷风险的企业。
 
 
5.2.	长沙知识图谱分析平台
融合涉T人物社交媒体行为数据、任职职位数据等构建基于涉台人物亲友关系及社交行为本体，从海量社交账号及新闻媒体中进行涉台人物知识抽取，从而分析涉台人物间多度隐秘干系，探索涉台人物社交行为规律，挖掘重点人物关联。
 
 
5.3.	疫情防控知识图谱
产品针对新冠肺炎疫情防控任务，在产品的基础上扩展了传播链条分析功能，结合地理信息系统实现了确诊病例的传播链条的快速发现与可视分析，为相关部门疫情防控快速发现、快速响应、快速追踪的流调任务贡献力量。
 

第六章 关键技术

基础自然语言处理模型是能够被再训练的模型，具备一定的开放性，这种模型可以根据用户的需求进行再定义，可以根据用户业务领域特点进行适配，满足更多通用用户业务应用场景的需要。
在本项目知识图谱构建所需的数据分析工作中，有许多场景需要用到语义分析相关技术对文本进行理解。
系统提供的模型管理模块提供了命名实体、属性、关系和事件类型等本体的定义功能，同时提供了通过本体构建知识图谱所用的自然语言处理相关的模型、算法和机器学习框架的管理功能。
6.1.	命名实体抽取
命名实体抽取（Named Entity Extraction）是一项自然语言处理任务，其目标是从给定的文本或语料库中识别和提取出具有特定命名实体类别的词语或短语。这些命名实体可以是人物、地点、组织机构、时间、日期、等。命名实体抽取可以帮助我们理解文本中的重要信息，并应用于诸如信息抽取、实体链接、文本分类和问答系统等应用中。
命名实体识别模型支持嵌套实体的抽取与识别。嵌套实体场景至少包括但不限于：相同类型的多个实体互相嵌套、不同类型的多个实体互相嵌套。 
为满足上述命名实体抽取需求，系统提供一些列自然语言处理模型及算法以方便用户进行实体抽取。
6.1.1.	卷积神经网络
系统集成卷积神经网络算法供用户使用，用户可以在算法仓库中查看该算法参数的含义，在创建训练任务时，可以通过可视化界面选择使用该算法，可以配置该算法的参数。
CNN在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。
卷积网络执行的是监督训练，所以其样本集是由形如：**（输入向量，理想输出向量）**的向量对构成的。所有这些向量对，都应该是来源于网络即将模拟系统的实际“运行”结构，它们可以是从实际运行系统中采集来。
1）参数初始化：
在开始训练前，所有的权都应该用一些不同的随机数进行初始化。“小随机数”用来保证网络不会因权值过大而进入饱和状态，从而导致训练失败；“不同”用来保证网络可以正常地学习。实际上，如果用相同的数去初始化权矩阵，则网络无学习能力。
2）训练过程包括四步
① 第一阶段：前向传播阶段
从样本集中取一个样本，输入网络。
计算相应的实际输出；在此阶段信息从输入层经过逐级的变换，传送到输出层，这个过程也是网络在完成训练之后正常执行时执行的过程。
② 第二阶段：后向传播阶段
计算实际输出与相应的理想输出的差
按照极小化误差的方法调整权值矩阵
网络的训练过程如下：
选定训练组，从样本集中分别随机地寻求N个样本作为训练组。
将各权值、阈值，置成小的接近于0的随机值，并初始化精度控制参数和学习率。
从训练组中取一个输入模式加到网络，并给出它的目标输出向量。
计算出中间层输出向量，计算出网络的实际输出向量。
将输出向量中的元素与目标向量中的元素进行比较，计算出输出误差，对于中间层的隐单元也需要计算出误差。
依次计算出各权值的调整量和阈值的调整量。
调整权值和调整阈值。
当经历M后，判断指标是否满足精度要求，如果不满足，则返回(3)，继续迭代；如果满足就进入下一步。
训练结束，将权值和阈值保存在文件中。这时可以认为各个权值已经达到稳定，分类器已经形成。再一次进行训练，直接从文件导出权值和阈值进行训练，不需要进行初始化。
6.1.2.	CRF模型
系统集成CRF模型供用户使用，用户可以在算法仓库中查看该算法参数的含义，在创建训练任务时，可以通过可视化界面选择使用该算法，可以配置该算法的参数。
在命名实体识别中，有些标签遵循着一定的逻辑关系，CRF能够充分利用标签相互间的关系，得到全局意义上的最佳标签序列。
CRF层的权重系数是一个(𝑘+2)×(𝑘+2)的矩阵𝐴，其中𝑘为语料中的标注类别数，𝐴𝑖𝑗表示从第𝑖个标签到第𝑗个标签的转移得分。考虑到需要在句子首尾各加上起止标签以界定句子边界，则矩阵的两个维度各加上2。若有与句子𝑥长度相同的标签序列𝑦=(𝑦1,𝑦2,...,𝑦𝑛)，则经过CRF得到𝑥的标签等于𝑦的打分如公式所示。
 
可以看到整个句子的打分由每个位置的LSTM层输出与CRF转移得分两部分之和算得。最后用算得归一化后输出的概率。如公式所示。
 
训练过程使用最大似然法，如公式所示。
 
预测时通过维特比算法来得到最优路径，如公式所示。
 
6.1.3.	多层感知机
系统集成多层感知机算法供用户使用，用户可以在算法仓库中查看该算法参数的含义，在创建训练任务时，可以通过可视化界面选择使用该算法，可以配置该算法的参数。
多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络。
多层感知机是由感知机推广而来，感知机学习算法用神经元的结构进行描述的话就是一个单独的。
感知机的神经网络表示如下：
 
图 感知机神经网络图
多层感知机在单层神经网络的基础上引入了一到多个隐藏层（hidden layer）。隐藏层位于输入层和输出层之间。图展示了一个多层感知机的神经网络图。
 
图 多层感知机神经网络图
多层感知机的学习能力比单个感知机强得多，但随着其结构的复杂化，对应的训练方法也不同于前面简单感知机的简单规则，最常使用的方法是误差逆传播（error BackPropgation，即常用的BP算法）。
算法过程：
对一个给定的训练集D={(x1,y1),(x2,y2)...(xm,ym)}，其中xi为d维向量，yi为l维向量，即自变量由d个维度组成，输出值为l个维度，对应的，构造一个由d个输入层神经元、q个隐含层神经元（隐含层神经元个数没有硬性要求）以及l个输出层神经元组成的单隐层前馈神经网络，其中输出层第j个神经元的阈值用θj表示，隐层第h个神经元的阈值用γh表示，输入层第i个神经元与隐层第h个神经元之间的连接权为vih，隐层第h个神经元与输出层第j个神经元之间的连接权为whj，记隐层第h个神经元接收到的输入为：
 
输出层第j个神经元接收到的输入为：
 
结构如下图：
 
6.1.4.	迁移学习
系统集成生成迁移学习算法供用户使用，用户可以在算法仓库中查看该算法参数的含义，在创建训练任务时，可以通过可视化界面选择使用该算法，可以配置该算法的参数。
迁移学习（Transfer Learning）属于机器学习的一种研究领域。它专注于存储已有问题的解决模型，并将其利用在其他不同但相关问题上。如说，用来辨识汽车的知识（或者是模型）也可以被用来提升识别卡车的能力，其功能类似于“举一反三”。在税务业务中往往因为信息收集不全面、管理系统的缺陷而疏漏可被不法企业、团体和个人利用的漏洞，进而可能造成重大经济损失。迁移学习可以针对已有的不全面数据进行学习，再利用本身的特性去识别和发现潜在漏洞。
迁移学习四种基本方法：样本迁移、特征迁移、模型迁移、关系迁移。
样本迁移（Instance based TL）
在源域中找到与目标域相似的数据，把这个数据的权值进行调整，使得新的数据与目标域的数据进行匹配。下图的例子就是找到源域的例子3，然后加重该样本的权值，使得在预测目标域时的比重加大。优点是方法简单，实现容易。缺点在于权重的选择与相似度的度量依赖经验，且源域与目标域的数据分布往往不同。
特征迁移（Feature based TL）
假设源域和目标域含有一些共同的交叉特征，通过特征变换，将源域和目标域的特征变换到相同空间，使得该空间中源域数据与目标域数据具有相同分布的数据分布，然后进行传统的机器学习。优点是对大多数方法适用，效果较好。缺点在于难于求解，容易发生过适配。
模型迁移（Parameter based TL）
假设源域和目标域共享模型参数，是指将之前在源域中通过大量数据训练好的模型应用到目标域上进行预测，比如利用上千万的图象来训练好一个图象识别的系统，当我们遇到一个新的图象领域问题的时候，就不用再去找几千万个图象来训练了，只需把原来训练好的模型迁移到新的领域，在新的领域往往只需几万张图片就够，同样可以得到很高的精度。优点是可以充分利用模型之间存在的相似性。缺点在于模型参数不易收敛。
 
图 模型迁移图
关系迁移（Relation based TL）
假设两个域是相似的，那么它们之间会共享某种相似关系，将源域中逻辑网络关系应用到目标域上来进行迁移，比方说生物病毒传播到计算机病毒传播的迁移。
 
图 关系迁移图
6.2.	关系抽取
关系抽取就是从文本中抽取出三元组，用英文表示就是(subject, relation, object)这样的三元组。所以关系抽取，也叫作三元组抽取。从关系抽取的定义也可以看出，关系抽取主要任务：
识别文本中的subject和object（实体识别任务）
判断这两个实体属于哪种关系（关系分类）。
关系提取有五种不同的方法：
（1）基于规则的关系提取
（2）弱监督关系提取
（3）监督关系提取
（4）模糊监督关系提取
6.2.1.	基于规则的关系提取
许多实体的关系可以通过手工模式的方式来提取，寻找三元组(X,α,Y)，X是实体，α是实体之间的单词。比如，“Paris is in France”的例子中，α=“is”。这可以用正则表达式来提取。
 
句子中的命名实体
 
句子中的词性标记
仅查看关键字匹配也会检索出许多假阳性。我们可以通过对命名实体进行过滤，只检索(CITY、is in、COUNTRY)来缓解这种情况。我们还可以考虑词性(POS)标记来删除额外的假阳性。
	这些是使用word sequence patterns的例子，因为规则指定了一个遵循文本顺序的模式。然而这些类型的规则对于较长范围的模式和具有更大多样性的序列来说是不适用的。例如：“Fred and Mary got married”就不能用单词序列模式来成功地处理。
 
句子中的依赖路径
相反，我们可以利用句子中的从属路径，知道哪个词在语法上依赖于另一个词。这可以极大地增加规则的覆盖率，而不需要额外的努力。
我们也可以在应用规则之前对句子进行转换。例如：“The cake was baked by Harry”或者“The cake which Harry baked”可以转化成“Harry bake The cake”。然后我们改变顺序来使用我们的“线性规则”，同时去掉中间多余的修饰词。
6.2.2.	弱监督的关系提取
这里的思想是从一组手工编写的规则开始，通过迭代的方式从未标记的文本数据中自动找到新的规则。或者，你可以从一个种子元组开始，用特定的关系描述实体。例如，seed={(ORG:IBM, LOC:Armonk)， (ORG:Microsoft, LOC:Redmond)}表示具有“based in”关系的实体。
 
弱监督关系提取
Snowball是一个相当古老的算法示例，它可以实现以下功能：
（1）从一组种子元组开始(或使用一些手工规则从未标记的文本中提取一组种子)。
（2）从未标记的文本中提取和元组匹配的共现词，并用NER(命名实体识别器)标记它们。
（3）为这些事件创建模式，例如“ORG is based in LOC”。
（4）从文本中生成新的元组，例如(ORG:Intel, LOC: Santa Clara)，并添加到种子集中。
（5）执行步骤2或终止并使用创建的模式进行进一步提取。
6.2.3.	有监督的关系提取
进行监督关系提取的一种常见方法是训练一个层叠的二分类器(或常规的二分类器)来确定两个实体之间是否存在特定的关系。这些分类器将文本的相关特征作为输入，从而要求文本首先由其他NLP模型进行标注。典型的特征有：上下文单词、词性标注、实体间的依赖路径、NER标注、tokens、单词间的接近距离等。
可以通过下面的方式训练和提取：
（1）根据句子是否与特定关系类型相关或不相关来手动标注文本数据。例如“CEO”关系：“Apple CEO Steve Jobs said to Bill Gates.” 是相关的，“Bob, Pie Enthusiast, said to Bill Gates.”是不相关的。
（2）如果相关句子表达了这种关系，就对正样本/负样本进行手工的标注。“Apple CEO Steve Jobs said to Bill Gates.”：(Steve Jobs, CEO, Apple) 是正样本，(Bill Gates, CEO, Apple)是负样本。
（3）学习一个二分类器来确定句子是否与关系类型相关。
（4）在相关的句子上学习一个二分类器，判断句子是否表达了关系。
（5）使用分类器检测新文本数据中的关系。
6.2.4.	模糊监督的关系提取
我们可以将使用种子数据(比如弱监督的RE)和训练分类器(比如有监督的RE)的思想结合起来。但是，我们可以从现有的知识库(KB)，比如Wikipedia、DBpedia、Wikidata、Freebase、Yago中得到种子，而不是自己提供一组种子元组。
 
模糊监督
模糊监督的关系抽取方法：
（1）对于知识库中我们感兴趣的每个关系类型进行循环。
（2）对于知识库中该关系的每个元组进行循环。
（3）从我们的未标记文本数据中选择可以匹配到这些元组的句子(元组的两个单词在句子中是共现的)，并假设这些句子是这种关系类型的正样本。
（4）从这些句子中提取特征(如词性、上下文词等)。
（5）训练一个有监督的分类器。
6.2.5.	关系抽取常用模型：
6.2.5.1.	CASREL模型
早期的工作，将关系抽取视为pipeline的任务：先做一个NER，识别出sentence中所有的entity；然后再对每个实体pair做relation classification(RC)，这种pipeline的方式存在错误传递，即NER出现错误，那么显然RC任务也必然出错。本文的观点是将关系抽取视作一个映射函数：从subject 到 (object, relation)。
先做实体识别，再做关系抽取： 
本文的工作:  
 
 CASREL模型架构
大致处理流程：
（1）通过BERT编码sentence  
（2）subject抽取：这里是对subject做了一个span抽取，即两个独立的二分类器：当前token是否是subject的开始/结尾。
（3）object抽取：因为是希望做 ，那么做object抽取时需要融入subject信息。
subject信息编码：取subject span起始位置（训练时，用的是golden label的span区间）两个token对应的embedding，按位加之后求平均得到 ，那么token i对应的embedding变为 
object抽取：这里对每个token做relation num ∗ 2个独立的二分类, 即对每种relation，都做一次独立的object span抽取。
 
6.2.5.2.	TPLinker模型
TPLinker模型主要针对关系重叠问题提出的联合抽取模型。联合抽取模型 TPLinker，它能够发现共享一个或两个实体的重叠关系，同时不受暴露偏差的影响。TPLinker 将联合抽取描述为一个 token 对链接问题，并引入了一种新的握手标记方案，该方案将实体对中每个关系类型下的边界标记对齐。
 
如上图所示，一共有三种握手标记，紫色代表两实体各自内部的头尾握手，红色代表两实体头握手，蓝色代表两实体的尾握手。同一种颜色的握手标记，会被表示在同一个矩阵，接下来介绍这三个矩阵。
①表示两个实体内部的头与尾
 
②标记两个实体头token
 
③标记两个实体的尾token
 
优化内存：
上述的①号矩阵中，其标记点不可能出现在下三角区域，故可直接丢弃下三角区域；而对于②，③号矩阵，其标记点可能出现在下三角区域，但可以先把标记点映射到上三角区域，再丢弃下三角区域，注意：映射到上三角区域的标记点，记为“2”，而非“1”。
 
模型结构:
模型比较简单，整个句子过一遍 encoder，然后将 token 两两拼接输入到一个全连接层，再激活一下输出作为 token 对的向量表示，最后对 token 对进行分类即可。换句话说，这其实是一个较长序列的标注过程。
 
6.2.5.3.	PRGC模型
PRGC将关系抽取分解成三个任务：关系判断、实体抽取和主客体对齐。首先通过关系判断模块获取文本中蕴含的关系，过滤掉不可能存在的关系。接着，将关系信息加入到实体抽取模块，每种关系都抽取出相应的主客实体。最后，使用主客体对齐模块获取的全局实体相关矩阵将主客实体进行对齐，从而抽取出文本所对应的三元组。
 
6.3.	属性抽取
属性抽取目标是从不同信息源中采集特定实体的属性信息。比如人物实体的生日、性别、国籍等，都是它的属性信息，通过属性抽取，通过多个数据源的获取，我们就可以通过丰富的属性信息来较为完整地刻画一个实体。
6.3.1.	基于规则的槽填充算法
场景：在纯文中的抽取人物属性。
论文：《中文人物属性槽填充技术的研究与实现》。
方法：通过人工编写规则针对任务场景进行属性抽取，由于人工构造规则模板比较麻烦，可以使用Booststrapping方法生成规则。
生成规则的步骤：
①、人工置顶规则种子作为初始化规则种子集Spatter，属性值集合Sattr。
②、使用规则种子集Spattr，遍历并匹配文本中的属性值，获取候选属性集合h。
 ③、计算候选属性值集合h中每个属性值的可行度，将可信度较高的三个属性值加入到种子属性值集合Sattr中，若收敛，则算法结束，否则，执行④。
④、使用属性值集合Sattr，遍历文本，由匹配到的属性值的上下文两个词，生成候选模板集合h’。
⑤、计算候选模板集合h’中每个候选模板的可信度，将可信度较高的3个候选模板加入到规则种子集合Spatter中，若Spatter收敛，则算法结束，否则执行步骤②。
重复②-⑤到满足一定的次数。
效果：通过自动生成规则进行抽取的效果不好，准确率较低。
6.3.2.	基于聚类的属性抽取
场景：产品的属性抽取
论文：《An Unsupervised Approach to Product Attribute Extraction》
方法步骤：
①、数据预处理：
找出限定性的短语和名词短语，论文认为一般属性出现在这种词语中
②、对上一步筛选出的名词进行聚类，删除词语稍少的类
③、从类中抽取属性：计算unigrams, bigrams and trigrams，使用作者定义的属性分数函数进行计算，得分高的则为属性。
6.3.3.	基于依存关系的半监督的槽填充算法
场景：在纯文本中抽取人物属性
论文：《中文人物属性槽填充技术的研究与实现》
方法：
依存关系：在自然语言处理中，用词与词之间的依存关系来描述语言结构的框架称为依存语法(dependence grammar)，又称从属关系语法。利用依存句法进行句法分析也是自然语言理解的重要技术之一。(来自维基百科)。
使用这种方法对人物进行属性抽取的步骤如下:
①、为每个属性生成对应的触发词表（词典）；
②、根据属性槽特点，识别出句子中所有可能候选属性，比如出生地的NER标注为LOC，感觉是自己设置一些规则匹配一些属性出来；
③、通过句子的依存结构，确认侯选属性与主体实体(这里是人物)的关系。将依存关系树看作一个无向图，顶点对应pagerank算法中的网页，利用pagerank算法，计算两个词在句法上的相关性。
④、计算<动词，人名，属性词>三元组的得分，取前top4，看动词是否出现在触发词中。
效果：在有触发词的句子中效果较好，在描述句式灵活且对触发词依赖小的句子中，提取性能不好。
6.3.4.	基于深度学习的序列标注
序列标注属于一种较为常用的属性抽取方法，就是将属性值看作较长的实体值，对数据进行标注，使用序列标注模型进行训练和抽取。
场景：这种方法被应用于多个场景中，比如人物属性的抽取，抽取在线评论文本的属性、从无上下文信息的标题中抽取产品属性等，只要有相应的标注数据，就可以使用这种方法进行抽取。
论文：《基于弱监督的属性关系抽取方法》
《面向非结构化文本的开放式实体属性抽取》
《实体 —属性抽取的GRU+CRF方法》
《Personal Attributes Extraction in Chinese Text Based on Distant-Supervision and LSTM》
《Bootstrapped Named Entity Recognition for Product Attribute Extraction》等论文中都使用了这种方法进行抽取。
方法：将属性抽取看作序列标注问题，标注需要花费一定的人工成本，在有些场景下，比如人物属性的抽取，可以使用百度百科等百科词条的结构化信息框进行标注，可以降低一定的人工标注成本；同时，标注时也可以使用Bootstrap方法由种子发现更多潜在属性值，这种方法在《Bootstrapped Named Entity Recognition for Product Attribute Extraction》论文中提到，是一种类似于Pakhomov 2002提出的首字母扩写算法的算法。该算法学习如何将首字母缩写与其正确扩展相关联的上下文，作者认为，分类器在经过标记的已知品牌训练集上进行训练，可以学习可以区分当前含义的上下文模式。序列标注常使用的模型：CRF模型、神经网络模型如BI-GRU+CRF模型等。
效果：使用这种方法进行属性抽取的效果较为理想，但也具有一定的局限性，由于属性值的内容和形式多种多样，对于字数较长的描述性属性，这种方法不能取得理想的效果；同时，对于某些不能使用百科词条数据进行回标的情况，将花费大量的人工成本进行标注，降低了可操作性。
6.3.5.	基于元模式的属性抽取
场景：这种方法可以被应用于多个场景中，不具有局限性。
6.4.	事件抽取
事件抽取是把含有事件信息的非结构化文本以结构化的形式呈现出来，在自动文摘、自动问答、信息检索等领域有着广泛的应用。近些年来 ,事件抽取一直吸引着许多研究机构和研究者的注意力。MUC (Message Understanding Conference) 会议、ACE ( Automatic Content Extraction) 会议是典型的含有事件抽取任务的评测会议。在调研中发现，ACE 2005作为论文数据集占据了主流，ACE 2005的事件抽取数据集包括英文、中文和阿拉伯语。因此围绕ACE来介绍事件抽取的定义、事件类型等，以ACE 2005为例对事件进行介绍。
ACE定义中的事件由事件触发词(Event Trigger)和描述事件结构的元素(Argument)构成。事件触发词事件触发词(trigger)是能够触动事件发生的词，是决定事件类型最重要的特征词，决定了事件类别/子类别。元素用于填充事件模版，两者完整的描述了事件本身。
事件抽取任务可以由下面两个步骤主要组成：
事件检测(Event Detection)：主要是根据上下文识别出触发词以及代表的事件类型和子类型，ACE2005定义了8种事件类别以及33种子类别，每种事件类别/子类别 对应唯一的事件模版。
事件元素识别(Argument Detection)：事件元素是指事件的参与者。根据所属的事件模版，抽取相应的元素，并为其标上正确的元素标签。
从理论发展的角度看，事件抽取的相关研究，有助于我们深入了解任机器理解数据、理解世界的机制，也有助于我们了解自身的认知机制，作为一种方法对人工智能之外领域的研究也是非常有意义的。从应用的角度看，事件抽取技术可以帮助我们解决很多现实问题，比如前面提到的海量信息的自动处理。
事件抽取模型的核心构成
（1） 事件类型体系，以及各类事件里重要的角色，统称为schema。
（2） 信息抽取方法。
6.4.1.	Schema的制定
事件抽取任务的起点，是需求的出现。关心金融领域的朋友，比如我(持有市值约370元人民币的基金)，希望了解所有可以影响市场情绪的事件。因此，海量新闻数据中识别特定类型的事件就是我们的需求。
需求确定了，接下来的任务就是把需求转换为人和机器都可以理解的一种形式，即制定事件的schema。“schema”即纲要，是我们对事物一般的、抽象的描述，体现人类对事物的认知水平，决定了机器抽取事件的能力，因此非常重要。一个完整的事件schema，应当包括：
（1）事件类型体系，比如“企业成立”、“企业并购”等等组成的，就是我关心的事件的类型体系；
（2）各类事件的重要角色，比如表2-1所示的各个字段，就是一个事件得以发展所依赖的重要角色。有时候，我们会设置一种特殊的角色，即“事件触发词”，用来辅助判断事件的发生。
确定了schema，一方面方便大家在相同的概念基础上展开协作，另一方面也让机器有了相对确定的学习和预测目标。
6.4.2.	信息的抽取方法
事件抽取的schema和知识图谱的schema是同一概念，类似“语义槽”，需要从原始数据中抽取特定的片段来填写，就像表2-1的“例子”一栏一样。至此，我们就进入到了事件抽取任务的第二个子任务，即信息抽取模型构建——换句话说，我们需要构建一定的工具，让它从半结构化、非结构化数据中，把schema描述的信息抽取出来。
目前的主流做法，是用两个子任务完成信息的抽取：
（1）识别事件并判断类型。可以用序列元素分类的方式识别触发词并判断事件类型，或者直接使用文本分类的方式判断mention对应的事件类型。
（2）识别事件角色。用序列元素分类，或者三元组抽取的方式，把事件的重要角色识别出来并分类。
6.4.3.	基于模式匹配的事件抽取方法
基于模式匹配的事件抽取方法：对某种类别事件的识别和抽取是在某一些模式的指导下进行的，匹配的过程就是事件识别和事件抽取的过程。
过程：模式获取和模式匹配。模式准确性尤为重要。
6.4.4.	有监督的事件模式匹配
模式的获取完全基于人工标注的语料，学习效果高度依赖人工标注效果。
步骤：
	语料的人工标注：需人工预先标注大量的语料。
	模式的学习：通过各种学习模型方法得到相应的抽取模式。
	模式的匹配：利用学习得到的模式与待抽取文档进行匹配，进而完成事件抽取。
6.4.5.	弱监督的事件模式匹配
不需要对语料完全标注，只需要人工对语料进行一定的预分类或者制定少量种子模式，由机器根据预分类语料或者种子模式自动学习事件模式。
步骤：
	语料的人工预分类或种子模式的制定
	模式的学习：利用机器根据预分类语料或者种子模式自动学习事件模式。
	优缺点：
在特定领域中性能较好。然而，依赖于文本的具体形式，获取模板的过程费时费力，具有很强的专业性，而且制定的模式很难覆盖所有的事件类型，当语料发生变化时，需要重新获取模式。可移植性不强，召回率低。
6.4.6.	基于机器学习的事件抽取方法
根据所需监督数据不同，可分为：有监督事件抽取方法和弱监督事件抽取方法。
6.4.7.	有监督事件抽取方法
步骤：训练样本的表示。eg：基于特征向量方法中特征向量的抽取与构建选择分类器并训练模型，优化参数，未标注数据中事件抽取。
6.4.8.	基于特征工程的方法
需显式地将 事件实例 =》特征向量（如何提取具有区分性的特征）。
步骤：
	特征抽取：提取词汇、句法和语义等特征并收集起来，产生描述事件实例的各种局部和全局特征。
	模型训练：训练分类器
	事件抽取：用分类器对非结构化文本进行分类，进而完成事件抽取。
	典型方法：2006年，Ahn提出的一个两阶段的多分类问题。
	词汇特征：词汇，词汇小写形式，词干，词性标签，相邻词特征。
	句子级特征：依存路径，依存词汇，候选词在依存树的深度，依存词汇的词性标签，句子中的实体类型，最近距离范围内的实体类型等。
	外部知识：在wordnet中的同义词id。
	不足：过程过分依赖词性标注器、句法分析器等传统的NLP工具 ==》造成累计误差很多语言没有NLP工具。
6.4.9.	基于神经网络的方法
步骤：
	特征表示：将纯文本表示为分布式特征信息，eg：词表示为词向量。
	神经网络的构建与高层特征学习：涉及搭建神经网络模型并基于基本特征自动捕获高层特征。
	模型训练：利用标注数据，优化网络参数，训练网络模型。
	模型分类：利用训练的模型对新样本进行分类，进而完成事件抽取。
	典型方法：2015，动态多池化卷积神经模型，该方法将事件抽取当作一个二阶段的多分类问题，第一阶段为触发词抽取，第二阶段为元素抽取（更为复杂，以此为例进行说明）。
	词向量学习：通过非监督信息得到每个词的向量化表示。
	词汇级特征表示：利用词向量捕获词汇级语义。将候选词（候选触发词和候选事件元素）的词向量和候选词上下文的词向量拼接起来作为事件元素抽取段的词汇级表示。
	句子级特征表示：利用动态多池化CNN学习句子内部的组合语义特征。
为了处理一句话有多个事件的情况，利用动态多池化技术，根据触发词和候选元素动态地捕获一个句子中的事件信息。
	事件元素分类：利用Softmax分类器为每个候选事件元素计算扮演不同角色的概率。
模型训练：定义训练的目标函数，然后利用随机梯度下降等训练方法优化模型参数，进而训练整个网络的参数。为防止过拟合，可使用Adadelta等更新规则。
6.4.10.	弱监督事件抽取方法
有监督方法：人工标记数据耗时费力、一致性差，尤其在面向海量异构的网络数据时。
无监督方法：得到的事件信息没有规范的语义标签（事件类别、角色名称等）。
弱监督方法：为了得到规范的语义标签，需要给出具有规范语义标签的标注训练数据，与有监督方法不同，获得大规模标注语料（关键）的途径主要有两种：
利用 Bootstrapping 方法扩展语料。首先人工标注部分数据，然后自动扩展数据规模。
利用 Distant Supervison 方法自动生成大规模语料。主要利用结构化的事件知识回标非结构化文本，获取大规模训练样本后完成事件的抽取。
6.4.11.	基于 Bootstrapping 的事件抽取
核心思想：首先利用小部分标记数据训练抽取模型，然后利用训练好的模型对未标注数据进行分类，从中选取高置信度的结果加入到训练数据中，再次训练分类器，上述过程反复迭代进而完成标注数据的自动扩充和事件的自动抽取。
现状：基于弱监督的事件抽取方法还处于起步阶段，迫切需要自动生成大规模的、高质量的标注数据法人方法来提升性能。
6.4.12.	基于Distant Supervison的事件抽取
核心思想：首先提出回标的假设规则（即 Distant Supervison），然后利用结构化事件知识去非结构化文本中进行回标，将回标的文本当作标注样本，然后利用标注的样本训练模型，进而完成事件的抽取。
代表方法：2017年，Chen提出的事件语料的大规模自动生成方法。
核心元素检测：自动区分每个类型的事件中元素的重要程度并找到每个事件类型的核心事件元素。
事件触发词检测：利用核心元素回标可能包含相应事件实例的句子并检测其中的事件触发词。
事件触发词过滤和扩展：用语言学知识FrameNet过滤上一模块中发现的噪声触发词，并扩展确实的触发词，进而提高触发词的正确率和召回率。
标注数据的自动生成：利用本文提出的远距离监督方法自动从非结构化文本中标注事件信息。
不足：该方法无法自动生成篇章级标注数据并进行篇章级事件抽取（具有重要价值和现实意义）。
开放域事件抽取：
开放域事件抽取主要基于无监督的方法，该方法主要基于分布假设（Distributional Hypothesis）理论，将候选词的上下文作为表征事件语义的特征。按照所用方法的不同，可分为 基于内容特征的事件抽取方法 和 基于异常检测的事件抽取方法。
无监督事件抽取的关键：寻找更好的文本表示方式、文本相似度衡量指标难以应用到其他NLP任务中。
1、基于内容特征的事件抽取方法
步骤：
文本表示：对表示事件的句子、段落或者文档进行预处理，并表示为同一的特征形式，为后面的模块做准备。
事件聚类与新事件发现：基本文本表示，利用无监督方法将同类事件表示聚类，并发现新事件。
代表方法：1998年，Yang等提出 组平均聚类方法。
文本表示：对每篇文档首先进行句子划分和去停用词等预处理操作，然后对篇章中的词计算TF-IDF并据此进行排序，利用 Top K 个词的 TF-IDF 值组成的特征向量代表整个篇幅。
事件聚类与新事件发现：组平均聚类方法（Group Average Clustering）。
① 将待聚类文本按时间顺序排序，把每篇文档都当作一个类。（原因：数据观察得出，新闻对事件的报告在时间上具有时效性（一般周期为两个月）和集中性）
② 将现有的结果划分成连续但不重叠的固定个数的部分。
③ 对每个部分利用聚类算法进行聚类，将底层的类聚类为高层的类。知道每个部分聚类为指定的规模。
④ 取消部分的边界限制，对所有的类进行聚类，并更新第②步中的划分。
⑤ 重复第②~⑤步，直到所有的类别到达指定的规模。
不足：可以发现新的事件，但其发现的新事件往往是相似模板的聚类，难以规则化，很难被用于构建知识库，需要将其同现有知识库的事件框架进行对齐，或者通过人工方式来给每个聚类事件簇赋予语义信息。
2、基于异常检测的事件抽取方法
基本假设：某个重大事件的发生会导致新闻媒体或社交网络上涌现出大量的相关报道或讨论；反之关于某一主题的报道或讨论突然增多则暗示着某一重大事件的发生。
通用方法：对文档整体的异常情况进行分析 或 对每个词频进行异常检测。
事件关系抽取：
核心任务：以事件为基本语义单元，实现事件逻辑关系的深层检测和抽取。
现状：目前没有清晰统一的框架和定义，比较公认的有事件共指关系、事件因果关系、子事件关系和事件时序关系等。
1、事件共指关系
定义：当两个事件指称项指向真实世界的同一个目标事件，则认为这两个事件具有共指关系。有助于在多源数据中发现相同事件，对事件信息的不全和验证有积极作用。
eg：“2014年10月，联想集团正式完成对摩托罗拉移动的收购” 和 “联想集团以29.1亿美元的价格收购了摩托罗拉移动”描述的是同一个事件。
核心问题：计算两个指称项之间的相似度，一般会利用两类特征：
事件指称的文本语义相似度；
事件类型和事件元素之间的相似度
数据集：ECB（Event Coreference Bank）
2、事件因果关系
定义：因果关系反映了事件间先后相继、由因及果的一种关系。对文本的深层语义理解有重要意义，有助于掌握事件演变的过程，从而为决策者提供重要的决策信息。
难点：
因果关系错综复杂，一个事件的发生可能包含多个原因，须同时考虑多个因果事件间的传递作用。
eg：“睡前喝咖啡导致失眠”，“失眠导致上班迟到”，“上班迟到导致被老板批评”是一个因果关系链。
在某些情况下，单独从文本中很难抽取出因果关系，需要背景知识的辅助推断。
eg：“近日国家公布消息称在未来五年将继续加大对新能源汽车行业的扶持力度”和“今天比亚迪汽车的国家开盘10分钟就涨停了”。借助背景知识：“比亚迪是一家中国新能源汽车制造厂商。”，就可以推断出两个事件是因果关系。
3、子事件关系
定义：子事件关系反映了事件之间的粒度和包含关系，例如：“地震事件”一般包含“伤亡”、“救援”、“捐款”和“重建”等子事件。eg：连续报道、专题报道。
典型方法：基于先验的增量子事件学习模型、基于概率的贝叶斯网络结构学习方法、端到端的上下文相关的层次LSTM模型。
4、事件时序关系
定义：事件时序关系是指在时间上的先后顺序。可以辅助其他事件关系的发现。
目前，绝大多数事件时序关系的研究都集中在英文文本上，最广泛应用的语料是TimeBank；主流方法是基于机器学习方法的事件时序关系抽取，该类方法一般将事件时序关系识别转化为一个多分类问题。
6.4.13.	事件分类
随着社交媒体、新闻报道等信息众多，我们需要一种自动化的技术来对这些信息进行自动的检测和分类，以提供准确而高效的信息处理与分析。基于深度学习的事件检测与分类算法就应运而生。
事件检测是指自动化地从大量的文本信息中识别出与特定事件有关的信息，并对其进行分类和汇总。例如，在文本信息中识别与自然灾害相关的信息，将其分类为地震、飓风、洪水等。同时，这种算法可以进一步为响应和管理灾害的组织和机构提供决策支持。
深度学习是一种类似于神经网络的学习方式，它可以对文本信息、图像、语音等进行自动“学习”，然后根据所学到的特征来进行分类、识别等。对于事件检测，深度学习的方法可以通过学习与事件相关的文本和关键词，并将其归类到特定的事件中，从而直观地反映出事件的状态和趋势。
在深度学习技术中，常用的算法包括卷积神经网络(ConvolutionalNeuralNetworks，CNN)和循环神经网络 (Recurrent Neural Networks，RNN)。CNN主要用于图像处理中的物体识别和分割任务，而 RNN 则用于序列数据的处理，例如自然语言文本中的词序列。
对于事件检测中的文本信息，RNN 是一种比较有效的深度学习算法。以英语为例，每个单词被视为一个神经元，RNN根据单词序列的先后顺序来推断文本的意义。而在多语言环境下，深度学习算法可以通过相应的语言模型来进行处理，例如 Word2Vec 算法，它可以将每个单词向量化，从而在多语言环境下实现事件检测和分类。
在事件检测与分类算法方面，深度学习技术的应用领域有很多。例如，可以将其应用于社交媒体中的热点事件处理、新闻报道的分析、流行病的管理等方面。这些应用可以为政府部门、新闻媒体等提供重要的数据分析和支持。
 


